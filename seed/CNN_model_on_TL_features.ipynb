{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jluN2J5dmgBY",
        "outputId": "8108b706-26a3-425e-c85f-428eda7dda35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur2L0frTmZ0y"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"./drive/MyDrive/seed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDOrrlhem4fO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0S39jznhLCi"
      },
      "source": [
        "# start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdHnMQIfmZ1H"
      },
      "source": [
        "# Transfer Learning to extract feature vector and rearranging those feature vectors into 8*9 map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvzS0FCTmZ1I"
      },
      "outputs": [],
      "source": [
        "# we have already extrcated features with transfer learning and are saved in file extract_TL_features_inception_v3.py, \n",
        "# we will use those fetures which are already arranged in 8x9 map as an image to a cnn model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtG5KDxemZ1R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22fh08CvmZ1R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVATyGYSJ63C"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS1QeAJMVhzt"
      },
      "source": [
        "# kfold 5, batch size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYlSziosVg4L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPtljyNVVkau",
        "outputId": "e0035e7a-594b-45df-db2e-7a1760316604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJWhUHtKVkau"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"./drive/MyDrive/seed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osD45rmMVkav"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import Flatten, Dense, Concatenate, Reshape, LSTM\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,  classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "import keras\n",
        "# import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "from keras import backend as K\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYFgvJbLVkav"
      },
      "outputs": [],
      "source": [
        "num_classes = 3\n",
        "batch_size = 64\n",
        "img_rows, img_cols, fft_length, num_chan = 8, 9, 2048, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0sX5hOKVkav"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "\n",
        "# X = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/{i}_{i}_X_1D.npy\")\n",
        "y = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{i}_{i}_y.npy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRY2bR9mVkav",
        "outputId": "8c610ad9-98b8-433f-8ed1-0f0103e03b9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(987,)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VssiFIOVkav",
        "outputId": "43aeb65e-7e04-4c79-f704-0e445225c252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2961,)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "(array([-1.,  0.,  1.]), array([ 978,  963, 1020]))\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# one_y = np.array([y[:1697]] * 3).reshape((-1,))\n",
        "# one_y = to_categorical(one_y, num_classes)\n",
        "one_y_1 = np.array([y[:]]*3).reshape((-1,))\n",
        "print(one_y_1.shape)\n",
        "# for i in range(3378):\n",
        "#   if one_y_1[i] != y[(i%1126)]:\n",
        "#     print(\"break\")\n",
        "#     break\n",
        "print(one_y_1[0:10])\n",
        "print(np.unique(one_y_1, return_counts= True))\n",
        "one_y_1 = to_categorical(one_y_1, num_classes)\n",
        "print(one_y_1[0:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9peap7RVkaw",
        "outputId": "3caa16dd-7e18-4b50-f6dc-ada1176603aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2]), array([ 963, 1020,  978]))\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(one_y_1.argmax(1), return_counts= True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd_PjLUnVkaw"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AFY-PeRGVkaw",
        "outputId": "4e56a137-5d71-4b10-caac-c41297dc223c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "acc_list = []\n",
        "std_list = []\n",
        "all_acc = []\n",
        "acc_log = {}\n",
        "flag_for_model_summary = 0\n",
        "# with tf.device('/device:GPU:0'):\n",
        "for subject in range(1,16):  # 15 models for 15 subjects, no inter subject training, only intra subject\n",
        "    K.clear_session()\n",
        "    start = time.time()\n",
        "    falx = np.empty((0, 8, 9, 2048))\n",
        "    gc.collect()\n",
        "    for exp_id in range(1,4):\n",
        "      temp = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{subject}_{exp_id}_X89.npy\")\n",
        "      falx = np.vstack([falx, temp])\n",
        "      temp = None\n",
        "\n",
        "#     one_falx_1 = falx#.reshape(1008, 8, 9, 1280)\n",
        "\n",
        "    # ###============= random select ============####\n",
        "    # permutation = np.random.permutation(one_y_1.shape[0])\n",
        "    # one_falx_2 = one_falx_1[permutation, :]\n",
        "    # one_falx = one_falx_2[0:3400]\n",
        "    # one_y_2 = one_y_1[permutation, :]\n",
        "    # one_y = one_y_2[0:3400]\n",
        "    # ###============= random select ============####\n",
        "    one_y = one_y_1\n",
        "#     one_falx = one_falx_1[:,:,:,:]\n",
        "\n",
        "    print(one_y.shape)\n",
        "    print(falx.shape)\n",
        "    # x_train, x_test, y_train, y_test = train_test_split(one_falx, one_y, test_size=0.25)\n",
        "    seed = 7\n",
        "    np.random.seed(seed)\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "    cvscores = []\n",
        "\n",
        "\n",
        "    # create model\n",
        "    for k,(train, test) in enumerate(kfold.split(falx, one_y.argmax(1))):\n",
        "        img_size = (img_rows, img_cols, 2048)\n",
        "\n",
        "\n",
        "        def create_base_network(input_dim):\n",
        "\n",
        "            seq = Sequential()\n",
        "            seq.add(Conv2D(16, 3, activation='relu', padding='same', name='conv1',\n",
        "                           input_shape=input_dim))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            seq.add(Conv2D(32, 2, activation='relu', padding='same', name='conv2'))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            # seq.add(Conv3D(32, 3, activation='relu', padding='same', name='conv3'))\n",
        "            seq.add(Conv2D(8, 1, activation='relu', padding='same', name='conv4'))\n",
        "            seq.add(MaxPooling2D(2, 2, name='pool1'))\n",
        "            seq.add(Flatten(name='fla1'))\n",
        "            seq.add(Dense(16, activation='relu', name='dense1'))#, kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "#             seq.add(Reshape((1, 64), name='reshape'))\n",
        "\n",
        "            return seq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        base_network = create_base_network(img_size)\n",
        "        input_1 = Input(shape=img_size)\n",
        "#         input_2 = Input(shape=img_size)\n",
        "#         input_3 = Input(shape=img_size)\n",
        "#         input_4 = Input(shape=img_size)\n",
        "#         input_5 = Input(shape=img_size)\n",
        "#         input_6 = Input(shape=img_size)\n",
        "\n",
        "\n",
        "\n",
        "#         out_all = Concatenate(axis=1)(base_network(input_1))\n",
        "#         lstm_layer = LSTM(32, name='lstm')(out_all)\n",
        "        out_layer = Dense(3, activation='softmax', name='out')(base_network(input_1))\n",
        "        model = Model(input_1, out_layer)\n",
        "        # model.summary()\n",
        "        if flag_for_model_summary==0:\n",
        "          print(model.summary())\n",
        "          flag_for_model_summary = 1\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                      optimizer=tf.keras.optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "        # Fit the model\n",
        "        x_train = falx[train]\n",
        "        y_train = one_y[train]\n",
        "\n",
        "        x_test = falx[test]\n",
        "        y_test = one_y[test]\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        history = model.fit(x_train, y_train,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            epochs=150, batch_size=32, verbose=0,\n",
        "                            callbacks=[\n",
        "                                          tf.keras.callbacks.EarlyStopping(\n",
        "                                              monitor='val_accuracy',\n",
        "                                              patience=30,\n",
        "                                              restore_best_weights=True\n",
        "                                          )\n",
        "                                      ])\n",
        "\n",
        "        plt.plot(history.history['accuracy'], label='acc (training data)')\n",
        "        plt.plot(history.history['val_accuracy'], label='acc (validation data)')\n",
        "        plt.plot(history.history['loss'], label='loss (training data)')\n",
        "        plt.plot(history.history['val_loss'], label='loss (validation data)')\n",
        "        plt.title('training visualisation')\n",
        "        plt.ylabel('Value')\n",
        "        plt.xlabel('No. epoch')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # evaluate the model\n",
        "\n",
        "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "        print(\"%.2f%%\" % (scores[1] * 100)) # Accuracy\n",
        "        all_acc.append(scores[1] * 100)\n",
        "\n",
        "        y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(x_test))))\n",
        "        cm = confusion_matrix(y_test.argmax(1), y_pred)\n",
        "        clr = classification_report(y_test.argmax(1), y_pred, target_names=([\"0\",\"1\",\"2\"]))\n",
        "        plt.figure(figsize=(7, 7))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
        "        plt.xticks(np.arange(3) + 0.5, ([\"0\",\"1\",\"2\"]))\n",
        "        plt.yticks(np.arange(3) + 0.5, ([\"0\",\"1\",\"2\"]))\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "        print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "\n",
        "        print(f\"subject_no.:{subject}'s kfold:{k+1} completed\")\n",
        "\n",
        "\n",
        "\n",
        "    # print(\"all acc: {}\".format(all_acc))\n",
        "    print(\"mean acc: {}\".format(np.mean(all_acc)))\n",
        "    print(\"std acc: {}\".format(np.std(all_acc)))\n",
        "    acc_list.append(np.mean(all_acc))\n",
        "    std_list.append(np.std(all_acc))\n",
        "    print(\"subject_no.： {}\".format(subject))\n",
        "    acc_log[subject] = all_acc\n",
        "    all_acc = []\n",
        "    end = time.time()\n",
        "    print(\"%.2f\" % (end - start))   # run time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfhUoIwEVkax",
        "outputId": "235095b1-6c50-4b0a-b9f9-22c5fe4b7b6e"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1joQDTQVkax",
        "outputId": "794122f2-4a8c-4488-b1e0-76dc058acd8a"
      },
      "outputs": [],
      "source": [
        "print('Acc_all: {}'.format(acc_list))\n",
        "print('Std_all: {}'.format(std_list))\n",
        "print(\"Acc_mean: {}\".format(np.mean(acc_list)))\n",
        "print(\"Std_all: {}\".format(np.std(std_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3OJhODoVkax",
        "outputId": "3a558fa8-f79b-492c-cde2-9786f59485ff"
      },
      "outputs": [],
      "source": [
        "print(acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Iglzqe5Vkax"
      },
      "outputs": [],
      "source": [
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_list_k5.npy\", acc_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/std_list_k5.npy\", std_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_log_k5.npy\", acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZDvUg8hWJ7t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZngintKhWLwQ"
      },
      "source": [
        "# kfold 5 batch 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMtxVg3GWJ-r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tZxkWbDWP1t",
        "outputId": "9d8e37ef-e7e3-4db7-d302-a0678b47073f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CffdpYAsWP1u"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"./drive/MyDrive/seed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq-uQ_l8WP1u"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import Flatten, Dense, Concatenate, Reshape, LSTM\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,  classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "import keras\n",
        "# import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "from keras import backend as K\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u73uf5hfWP1u"
      },
      "outputs": [],
      "source": [
        "num_classes = 3\n",
        "batch_size = 64\n",
        "img_rows, img_cols, fft_length, num_chan = 8, 9, 2048, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5af_dIQSWP1u"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "\n",
        "# X = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/{i}_{i}_X_1D.npy\")\n",
        "y = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{i}_{i}_y.npy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUtrhpgVWP1u",
        "outputId": "c80d4283-3360-4c33-fd8e-7e895f666578"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(987,)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDUmwjxEWP1v",
        "outputId": "6784532d-7025-49eb-ca4e-409e4478a190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2961,)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "(array([-1.,  0.,  1.]), array([ 978,  963, 1020]))\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# one_y = np.array([y[:1697]] * 3).reshape((-1,))\n",
        "# one_y = to_categorical(one_y, num_classes)\n",
        "one_y_1 = np.array([y[:]]*3).reshape((-1,))\n",
        "print(one_y_1.shape)\n",
        "# for i in range(3378):\n",
        "#   if one_y_1[i] != y[(i%1126)]:\n",
        "#     print(\"break\")\n",
        "#     break\n",
        "print(one_y_1[0:10])\n",
        "print(np.unique(one_y_1, return_counts= True))\n",
        "one_y_1 = to_categorical(one_y_1, num_classes)\n",
        "print(one_y_1[0:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1bfkAs8WP1v",
        "outputId": "c6e2b81d-7e3d-4c82-88e4-06f0dfa20e49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2]), array([ 963, 1020,  978]))\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(one_y_1.argmax(1), return_counts= True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkmQFUNyWP1v"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T_xepVC0WP1v",
        "outputId": "348c786a-4072-4731-f61e-2efe3af68c6d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "acc_list = []\n",
        "std_list = []\n",
        "all_acc = []\n",
        "acc_log = {}\n",
        "flag_for_model_summary = 0\n",
        "# with tf.device('/device:GPU:0'):\n",
        "for subject in range(1,16):  # 15 models for 15 subjects, no inter subject training, only intra subject\n",
        "    K.clear_session()\n",
        "    start = time.time()\n",
        "    falx = np.empty((0, 8, 9, 2048))\n",
        "    for exp_id in range(1,4):\n",
        "      temp = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{subject}_{exp_id}_X89.npy\")\n",
        "      falx = np.vstack([falx, temp])\n",
        "      temp = None\n",
        "\n",
        "#     one_falx_1 = falx#.reshape(1008, 8, 9, 1280)\n",
        "\n",
        "    # ###============= random select ============####\n",
        "    # permutation = np.random.permutation(one_y_1.shape[0])\n",
        "    # one_falx_2 = one_falx_1[permutation, :]\n",
        "    # one_falx = one_falx_2[0:3400]\n",
        "    # one_y_2 = one_y_1[permutation, :]\n",
        "    # one_y = one_y_2[0:3400]\n",
        "    # ###============= random select ============####\n",
        "    one_y = one_y_1\n",
        "#     one_falx = one_falx_1[:,:,:,:]\n",
        "\n",
        "    print(one_y.shape)\n",
        "    print(falx.shape)\n",
        "    # x_train, x_test, y_train, y_test = train_test_split(one_falx, one_y, test_size=0.25)\n",
        "    seed = 7\n",
        "    np.random.seed(seed)\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "    cvscores = []\n",
        "\n",
        "\n",
        "    # create model\n",
        "    for k,(train, test) in enumerate(kfold.split(falx, one_y.argmax(1))):\n",
        "        img_size = (img_rows, img_cols, 2048)\n",
        "\n",
        "\n",
        "        def create_base_network(input_dim):\n",
        "\n",
        "            seq = Sequential()\n",
        "            seq.add(Conv2D(16, 3, activation='relu', padding='same', name='conv1',\n",
        "                           input_shape=input_dim))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            seq.add(Conv2D(32, 2, activation='relu', padding='same', name='conv2'))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            # seq.add(Conv3D(32, 3, activation='relu', padding='same', name='conv3'))\n",
        "            seq.add(Conv2D(8, 1, activation='relu', padding='same', name='conv4'))\n",
        "            seq.add(MaxPooling2D(2, 2, name='pool1'))\n",
        "            seq.add(Flatten(name='fla1'))\n",
        "            seq.add(Dense(16, activation='relu', name='dense1'))#, kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "#             seq.add(Reshape((1, 64), name='reshape'))\n",
        "\n",
        "            return seq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        base_network = create_base_network(img_size)\n",
        "        input_1 = Input(shape=img_size)\n",
        "#         input_2 = Input(shape=img_size)\n",
        "#         input_3 = Input(shape=img_size)\n",
        "#         input_4 = Input(shape=img_size)\n",
        "#         input_5 = Input(shape=img_size)\n",
        "#         input_6 = Input(shape=img_size)\n",
        "\n",
        "\n",
        "\n",
        "#         out_all = Concatenate(axis=1)(base_network(input_1))\n",
        "#         lstm_layer = LSTM(32, name='lstm')(out_all)\n",
        "        out_layer = Dense(3, activation='softmax', name='out')(base_network(input_1))\n",
        "        model = Model(input_1, out_layer)\n",
        "        # model.summary()\n",
        "        if flag_for_model_summary==0:\n",
        "          print(model.summary())\n",
        "          flag_for_model_summary = 1\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                      optimizer=tf.keras.optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "        # Fit the model\n",
        "        x_train = falx[train]\n",
        "        y_train = one_y[train]\n",
        "\n",
        "        x_test = falx[test]\n",
        "        y_test = one_y[test]\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        history = model.fit(x_train, y_train,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            epochs=150, batch_size=128, verbose=0,\n",
        "                            callbacks=[\n",
        "                                          tf.keras.callbacks.EarlyStopping(\n",
        "                                              monitor='val_accuracy',\n",
        "                                              patience=30,\n",
        "                                              restore_best_weights=True\n",
        "                                          )\n",
        "                                      ])\n",
        "\n",
        "        plt.plot(history.history['accuracy'], label='acc (training data)')\n",
        "        plt.plot(history.history['val_accuracy'], label='acc (validation data)')\n",
        "        plt.plot(history.history['loss'], label='loss (training data)')\n",
        "        plt.plot(history.history['val_loss'], label='loss (validation data)')\n",
        "        plt.title('training visualisation')\n",
        "        plt.ylabel('Value')\n",
        "        plt.xlabel('No. epoch')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # evaluate the model\n",
        "\n",
        "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "        print(\"%.2f%%\" % (scores[1] * 100)) # Accuracy\n",
        "        all_acc.append(scores[1] * 100)\n",
        "\n",
        "        y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(x_test))))\n",
        "        cm = confusion_matrix(y_test.argmax(1), y_pred)\n",
        "        clr = classification_report(y_test.argmax(1), y_pred, target_names=([\"0\",\"1\",\"2\"]))\n",
        "        plt.figure(figsize=(7, 7))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
        "        plt.xticks(np.arange(3) + 0.5, ([\"0\",\"1\",\"2\"]))\n",
        "        plt.yticks(np.arange(3) + 0.5, ([\"0\",\"1\",\"2\"]))\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "        print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "\n",
        "        print(f\"subject_no.:{subject}'s kfold:{k+1} completed\")\n",
        "\n",
        "\n",
        "\n",
        "    # print(\"all acc: {}\".format(all_acc))\n",
        "    print(\"mean acc: {}\".format(np.mean(all_acc)))\n",
        "    print(\"std acc: {}\".format(np.std(all_acc)))\n",
        "    acc_list.append(np.mean(all_acc))\n",
        "    std_list.append(np.std(all_acc))\n",
        "    print(\"subject_no.： {}\".format(subject))\n",
        "    acc_log[subject] = all_acc\n",
        "    all_acc = []\n",
        "    end = time.time()\n",
        "    print(\"%.2f\" % (end - start))   # run time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruuZQqCHWP1w",
        "outputId": "712e6ac8-254d-492a-83ae-5ed9dc5c4666"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilbMVTdFWP1w",
        "outputId": "3a3181f4-2797-43ea-aa66-376bbabb707b"
      },
      "outputs": [],
      "source": [
        "print('Acc_all: {}'.format(acc_list))\n",
        "print('Std_all: {}'.format(std_list))\n",
        "print(\"Acc_mean: {}\".format(np.mean(acc_list)))\n",
        "print(\"Std_all: {}\".format(np.std(std_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqWvfdBeWP1w",
        "outputId": "ffdd5648-d703-4e4c-93a5-98e2177d4ce0"
      },
      "outputs": [],
      "source": [
        "print(acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0laxip1VWP1w"
      },
      "outputs": [],
      "source": [
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_list_k5_128.npy\", acc_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/std_list_k5_128.npy\", std_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_log_k5_128.npy\", acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFFcrlhGWK2M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyOxLJ0sVYhu"
      },
      "source": [
        "# kfold 10, batch size 32\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR4bo0HAVWJv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1SRovtwVWM9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klP7DX83VWQR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLI1TOIaoVez",
        "outputId": "9dc2f6bf-8def-4050-f5a6-41f50df338ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjgH2b5aKPaG",
        "outputId": "f47be848-0fe1-4b28-fda1-82c54e7e552d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Apr 23 14:34:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXaVy2cXnEz4",
        "outputId": "a6b1ef27-3e93-43ba-c029-531de9bbd998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq9c9PTjw2hi",
        "outputId": "692441b4-9f8f-416e-adad-fb08b5e9c1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Apr 20 07:01:36 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoHskheT0P6W",
        "outputId": "b8e3ab13-af67-44c3-a042-b7249b46059a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nNGdNV4-QGj",
        "outputId": "a571140b-45c7-4fe2-a6c1-f5a3e3b683da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available\", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUKpGUlG_D7T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADp0Acw4_D9_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi-6rfO0mZ1U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL1hqeuHmZ1V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCXSoqzbmZ1V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlPFh9f6mZ1V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_fTaNFkmZ1V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihSpG8fJweE8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p6x5kLAmZ1V"
      },
      "outputs": [],
      "source": [
        "# %reset -f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ApL_TylmZ1V"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"./drive/MyDrive/seed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF4_XiRKmZ1V"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import Flatten, Dense, Concatenate, Reshape, LSTM\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,  classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "import keras\n",
        "# import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "from keras import backend as K\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOjRWGlZs7Hg"
      },
      "outputs": [],
      "source": [
        "num_classes = 3\n",
        "batch_size = 64\n",
        "img_rows, img_cols, fft_length, num_chan = 8, 9, 2048, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTZ2qJALmZ1W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eOZYc8ZmZ1W"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "\n",
        "# X = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/{i}_{i}_X_1D.npy\")\n",
        "y = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{i}_{i}_y.npy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgMkMegimZ1W"
      },
      "outputs": [],
      "source": [
        "# subject = 2\n",
        "# exp_id = 3\n",
        "\n",
        "# x89 = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_mobilenet_v2/{subject}_{exp_id}_X89.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZrCAUSlmZ1W"
      },
      "outputs": [],
      "source": [
        "# x89.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWBUTQ1pmZ1W",
        "outputId": "c7a5166a-4b2b-442c-ba85-173b88775c55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(987,)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwYJTRFmmZ1W",
        "outputId": "8f03de78-8c63-4794-fa66-7fe4a32f9ea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2961,)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "(array([-1.,  0.,  1.]), array([ 978,  963, 1020]))\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# one_y = np.array([y[:1697]] * 3).reshape((-1,))\n",
        "# one_y = to_categorical(one_y, num_classes)\n",
        "one_y_1 = np.array([y[:]]*3).reshape((-1,))\n",
        "print(one_y_1.shape)\n",
        "# for i in range(3378):\n",
        "#   if one_y_1[i] != y[(i%1126)]:\n",
        "#     print(\"break\")\n",
        "#     break\n",
        "print(one_y_1[0:10])\n",
        "print(np.unique(one_y_1, return_counts= True))\n",
        "one_y_1 = to_categorical(one_y_1, num_classes)\n",
        "print(one_y_1[0:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA8A9fvcmZ1W",
        "outputId": "e51852c3-1136-4afd-d5e1-e04a01ba0692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2]), array([ 963, 1020,  978]))\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(one_y_1.argmax(1), return_counts= True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uprDECfmZ1W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKXBRCN6mZ1X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSFww_qOmZ1X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YmIDoAfmZ1X"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GAxZFS5b_E-h",
        "outputId": "499703b3-25d7-4cf0-bbff-454e45866bb7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "acc_list = []\n",
        "std_list = []\n",
        "all_acc = []\n",
        "acc_log = {}\n",
        "flag_for_model_summary = 0\n",
        "# with tf.device('/device:GPU:0'):\n",
        "for subject in range(1,16):  # 15 models for 15 subjects, no inter subject training, only intra subject\n",
        "    K.clear_session()\n",
        "    start = time.time()\n",
        "    falx = np.empty((0, 8, 9, 2048))\n",
        "    for exp_id in range(1,4):\n",
        "      temp = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{subject}_{exp_id}_X89.npy\")\n",
        "      falx = np.vstack([falx, temp])\n",
        "      temp = None\n",
        "\n",
        "#     one_falx_1 = falx#.reshape(1008, 8, 9, 1280)\n",
        "\n",
        "    # ###============= random select ============####\n",
        "    # permutation = np.random.permutation(one_y_1.shape[0])\n",
        "    # one_falx_2 = one_falx_1[permutation, :]\n",
        "    # one_falx = one_falx_2[0:3400]\n",
        "    # one_y_2 = one_y_1[permutation, :]\n",
        "    # one_y = one_y_2[0:3400]\n",
        "    # ###============= random select ============####\n",
        "    one_y = one_y_1\n",
        "#     one_falx = one_falx_1[:,:,:,:]\n",
        "\n",
        "    print(one_y.shape)\n",
        "    print(falx.shape)\n",
        "    # x_train, x_test, y_train, y_test = train_test_split(one_falx, one_y, test_size=0.25)\n",
        "    seed = 7\n",
        "    np.random.seed(seed)\n",
        "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    cvscores = []\n",
        "\n",
        "\n",
        "    # create model\n",
        "    for k,(train, test) in enumerate(kfold.split(falx, one_y.argmax(1))):\n",
        "        img_size = (img_rows, img_cols, 2048)\n",
        "\n",
        "\n",
        "        def create_base_network(input_dim):\n",
        "\n",
        "            seq = Sequential()\n",
        "            seq.add(Conv2D(16, 3, activation='relu', padding='same', name='conv1',\n",
        "                           input_shape=input_dim))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            seq.add(Conv2D(32, 2, activation='relu', padding='same', name='conv2'))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            # seq.add(Conv3D(32, 3, activation='relu', padding='same', name='conv3'))\n",
        "            seq.add(Conv2D(8, 1, activation='relu', padding='same', name='conv4'))\n",
        "            seq.add(MaxPooling2D(2, 2, name='pool1'))\n",
        "            seq.add(Flatten(name='fla1'))\n",
        "            seq.add(Dense(16, activation='relu', name='dense1'))#, kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "#             seq.add(Reshape((1, 64), name='reshape'))\n",
        "\n",
        "            return seq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        base_network = create_base_network(img_size)\n",
        "        input_1 = Input(shape=img_size)\n",
        "#         input_2 = Input(shape=img_size)\n",
        "#         input_3 = Input(shape=img_size)\n",
        "#         input_4 = Input(shape=img_size)\n",
        "#         input_5 = Input(shape=img_size)\n",
        "#         input_6 = Input(shape=img_size)\n",
        "\n",
        "\n",
        "\n",
        "#         out_all = Concatenate(axis=1)(base_network(input_1))\n",
        "#         lstm_layer = LSTM(32, name='lstm')(out_all)\n",
        "        out_layer = Dense(3, activation='softmax', name='out')(base_network(input_1))\n",
        "        model = Model(input_1, out_layer)\n",
        "        # model.summary()\n",
        "        if flag_for_model_summary==0:\n",
        "          print(model.summary())\n",
        "          flag_for_model_summary = 1\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                      optimizer=tf.keras.optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "        # Fit the model\n",
        "        x_train = falx[train]\n",
        "        y_train = one_y[train]\n",
        "\n",
        "        x_test = falx[test]\n",
        "        y_test = one_y[test]\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        history = model.fit(x_train, y_train,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            epochs=150, batch_size=32, verbose=0,\n",
        "                            callbacks=[\n",
        "                                          tf.keras.callbacks.EarlyStopping(\n",
        "                                              monitor='val_accuracy',\n",
        "                                              patience=30,\n",
        "                                              restore_best_weights=True\n",
        "                                          )\n",
        "                                      ])\n",
        "\n",
        "        plt.plot(history.history['accuracy'], label='acc (training data)')\n",
        "        plt.plot(history.history['val_accuracy'], label='acc (validation data)')\n",
        "        plt.plot(history.history['loss'], label='loss (training data)')\n",
        "        plt.plot(history.history['val_loss'], label='loss (validation data)')\n",
        "        plt.title('training visualisation')\n",
        "        plt.ylabel('Value')\n",
        "        plt.xlabel('No. epoch')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # evaluate the model\n",
        "\n",
        "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "        print(\"%.2f%%\" % (scores[1] * 100)) # Accuracy\n",
        "        all_acc.append(scores[1] * 100)\n",
        "\n",
        "        y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(x_test))))\n",
        "        cm = confusion_matrix(y_test.argmax(1), y_pred)\n",
        "        clr = classification_report(y_test.argmax(1), y_pred, target_names=([\"0\",\"1\",\"2\"]))\n",
        "        plt.figure(figsize=(7, 7))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
        "        plt.xticks(np.arange(3) + 0.5, ([\"0\",\"1\",\"2\"]))\n",
        "        plt.yticks(np.arange(3) + 0.5, ([\"0\",\"1\",\"2\"]))\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "        print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "\n",
        "        print(f\"subject_no.:{subject}'s kfold:{k+1} completed\")\n",
        "\n",
        "\n",
        "\n",
        "    # print(\"all acc: {}\".format(all_acc))\n",
        "    print(\"mean acc: {}\".format(np.mean(all_acc)))\n",
        "    print(\"std acc: {}\".format(np.std(all_acc)))\n",
        "    acc_list.append(np.mean(all_acc))\n",
        "    std_list.append(np.std(all_acc))\n",
        "    print(\"subject_no.： {}\".format(subject))\n",
        "    acc_log[subject] = all_acc\n",
        "    all_acc = []\n",
        "    end = time.time()\n",
        "    print(\"%.2f\" % (end - start))   # run time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wAH-gXHnufQ"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt29SPlBnukN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T280E-BO_E-h",
        "outputId": "28a3834c-3548-43ea-b392-06c0f0630da7"
      },
      "outputs": [],
      "source": [
        "print('Acc_all: {}'.format(acc_list))\n",
        "print('Std_all: {}'.format(std_list))\n",
        "print(\"Acc_mean: {}\".format(np.mean(acc_list)))\n",
        "print(\"Std_all: {}\".format(np.std(std_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRlRfpiKnum4",
        "outputId": "052a2e85-e122-42d3-d8eb-5f21b90c8130"
      },
      "outputs": [],
      "source": [
        "print(acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzmVCgyLnupm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oySTEw2M_E-h"
      },
      "outputs": [],
      "source": [
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_list.npy\", acc_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/std_list.npy\", std_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_log.npy\", acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTWToQgMnusN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cpB1vvTnuuu"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCbquzK4nuxh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va88helTnuz1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y0dNr4IP-SZ"
      },
      "source": [
        "# kfold 10 batch 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJFM-VLOP-SZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR3lsVtzP-Sa"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"./drive/MyDrive/seed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF83Vj7TP-Sa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import Flatten, Dense, Concatenate, Reshape, LSTM\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,  classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "import keras\n",
        "# import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "from keras import backend as K\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARC6lCM9P-Sa"
      },
      "outputs": [],
      "source": [
        "num_classes = 3\n",
        "batch_size = 64\n",
        "img_rows, img_cols, fft_length, num_chan = 8, 9, 2048, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBUk0dLxP-Sa"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "\n",
        "# X = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/{i}_{i}_X_1D.npy\")\n",
        "y = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{i}_{i}_y.npy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQBWzJR0P-Sa",
        "outputId": "c7a5166a-4b2b-442c-ba85-173b88775c55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(987,)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owriqMqkP-Sa",
        "outputId": "8f03de78-8c63-4794-fa66-7fe4a32f9ea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2961,)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "(array([-1.,  0.,  1.]), array([ 978,  963, 1020]))\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# one_y = np.array([y[:1697]] * 3).reshape((-1,))\n",
        "# one_y = to_categorical(one_y, num_classes)\n",
        "one_y_1 = np.array([y[:]]*3).reshape((-1,))\n",
        "print(one_y_1.shape)\n",
        "# for i in range(3378):\n",
        "#   if one_y_1[i] != y[(i%1126)]:\n",
        "#     print(\"break\")\n",
        "#     break\n",
        "print(one_y_1[0:10])\n",
        "print(np.unique(one_y_1, return_counts= True))\n",
        "one_y_1 = to_categorical(one_y_1, num_classes)\n",
        "print(one_y_1[0:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvWCMFcmP-Sa",
        "outputId": "e51852c3-1136-4afd-d5e1-e04a01ba0692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2]), array([ 963, 1020,  978]))\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(one_y_1.argmax(1), return_counts= True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IzFJhuFP-Sb"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4bk8EWBdP-Sb",
        "outputId": "8683b92a-a484-461b-91eb-6f602b0799d3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "acc_list = []\n",
        "std_list = []\n",
        "all_acc = []\n",
        "acc_log = {}\n",
        "flag_for_model_summary = 0\n",
        "# with tf.device('/device:GPU:0'):\n",
        "for subject in range(1,16):  # 15 models for 15 subjects, no inter subject training, only intra subject\n",
        "    K.clear_session()\n",
        "    start = time.time()\n",
        "    falx = np.empty((0, 8, 9, 2048))\n",
        "    for exp_id in range(1,4):\n",
        "      temp = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{subject}_{exp_id}_X89.npy\")\n",
        "      falx = np.vstack([falx, temp])\n",
        "      temp = None\n",
        "\n",
        "#     one_falx_1 = falx#.reshape(1008, 8, 9, 1280)\n",
        "\n",
        "    # ###============= random select ============####\n",
        "    # permutation = np.random.permutation(one_y_1.shape[0])\n",
        "    # one_falx_2 = one_falx_1[permutation, :]\n",
        "    # one_falx = one_falx_2[0:3400]\n",
        "    # one_y_2 = one_y_1[permutation, :]\n",
        "    # one_y = one_y_2[0:3400]\n",
        "    # ###============= random select ============####\n",
        "    one_y = one_y_1\n",
        "#     one_falx = one_falx_1[:,:,:,:]\n",
        "\n",
        "    print(one_y.shape)\n",
        "    print(falx.shape)\n",
        "    # x_train, x_test, y_train, y_test = train_test_split(one_falx, one_y, test_size=0.25)\n",
        "    seed = 7\n",
        "    np.random.seed(seed)\n",
        "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    cvscores = []\n",
        "\n",
        "\n",
        "    # create model\n",
        "    for k,(train, test) in enumerate(kfold.split(falx, one_y.argmax(1))):\n",
        "        img_size = (img_rows, img_cols, 2048)\n",
        "\n",
        "\n",
        "        def create_base_network(input_dim):\n",
        "\n",
        "            seq = Sequential()\n",
        "            seq.add(Conv2D(16, 3, activation='relu', padding='same', name='conv1',\n",
        "                           input_shape=input_dim))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            seq.add(Conv2D(32, 2, activation='relu', padding='same', name='conv2'))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            # seq.add(Conv3D(32, 3, activation='relu', padding='same', name='conv3'))\n",
        "            seq.add(Conv2D(8, 1, activation='relu', padding='same', name='conv4'))\n",
        "            seq.add(MaxPooling2D(2, 2, name='pool1'))\n",
        "            seq.add(Flatten(name='fla1'))\n",
        "            seq.add(Dense(16, activation='relu', name='dense1'))#, kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "#             seq.add(Reshape((1, 64), name='reshape'))\n",
        "\n",
        "            return seq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        base_network = create_base_network(img_size)\n",
        "        input_1 = Input(shape=img_size)\n",
        "#         input_2 = Input(shape=img_size)\n",
        "#         input_3 = Input(shape=img_size)\n",
        "#         input_4 = Input(shape=img_size)\n",
        "#         input_5 = Input(shape=img_size)\n",
        "#         input_6 = Input(shape=img_size)\n",
        "\n",
        "\n",
        "\n",
        "#         out_all = Concatenate(axis=1)(base_network(input_1))\n",
        "#         lstm_layer = LSTM(32, name='lstm')(out_all)\n",
        "        out_layer = Dense(3, activation='softmax', name='out')(base_network(input_1))\n",
        "        model = Model(input_1, out_layer)\n",
        "        # model.summary()\n",
        "        if flag_for_model_summary==0:\n",
        "          print(model.summary())\n",
        "          flag_for_model_summary = 1\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                      optimizer=tf.keras.optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "        # Fit the model\n",
        "        x_train = falx[train]\n",
        "        y_train = one_y[train]\n",
        "\n",
        "        x_test = falx[test]\n",
        "        y_test = one_y[test]\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        history = model.fit(x_train, y_train,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            epochs=150, batch_size=128, verbose=0,\n",
        "                            callbacks=[\n",
        "                                          tf.keras.callbacks.EarlyStopping(\n",
        "                                              monitor='val_accuracy',\n",
        "                                              patience=30,\n",
        "                                              restore_best_weights=True\n",
        "                                          )\n",
        "                                      ])\n",
        "\n",
        "        plt.plot(history.history['accuracy'], label='acc (training data)')\n",
        "        plt.plot(history.history['val_accuracy'], label='acc (validation data)')\n",
        "        plt.plot(history.history['loss'], label='loss (training data)')\n",
        "        plt.plot(history.history['val_loss'], label='loss (validation data)')\n",
        "        plt.title('training visualisation')\n",
        "        plt.ylabel('Value')\n",
        "        plt.xlabel('No. epoch')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # evaluate the model\n",
        "\n",
        "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "        print(\"%.2f%%\" % (scores[1] * 100)) # Accuracy\n",
        "        all_acc.append(scores[1] * 100)\n",
        "\n",
        "        y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(x_test))))\n",
        "        cm = confusion_matrix(y_test.argmax(1), y_pred)\n",
        "        clr = classification_report(y_test.argmax(1), y_pred, target_names=([\"0\",\"1\",\"2\"]))\n",
        "        plt.figure(figsize=(7, 7))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
        "        plt.xticks(np.arange(3) + 0.5, ([\"0\",\"1\",\"2\"]))\n",
        "        plt.yticks(np.arange(3) + 0.5, ([\"0\",\"1\",\"2\"]))\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "        print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "\n",
        "        print(f\"subject_no.:{subject}'s kfold:{k+1} completed\")\n",
        "\n",
        "\n",
        "\n",
        "    # print(\"all acc: {}\".format(all_acc))\n",
        "    print(\"mean acc: {}\".format(np.mean(all_acc)))\n",
        "    print(\"std acc: {}\".format(np.std(all_acc)))\n",
        "    acc_list.append(np.mean(all_acc))\n",
        "    std_list.append(np.std(all_acc))\n",
        "    print(\"subject_no.： {}\".format(subject))\n",
        "    acc_log[subject] = all_acc\n",
        "    all_acc = []\n",
        "    end = time.time()\n",
        "    print(\"%.2f\" % (end - start))   # run time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-50sSq3JP-Sb",
        "outputId": "00491e86-ecec-444b-99a8-b75341c366c0"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWLKyB-nP-Sb",
        "outputId": "98b0527a-5044-4212-c20d-8f1a6963f747"
      },
      "outputs": [],
      "source": [
        "print('Acc_all: {}'.format(acc_list))\n",
        "print('Std_all: {}'.format(std_list))\n",
        "print(\"Acc_mean: {}\".format(np.mean(acc_list)))\n",
        "print(\"Std_all: {}\".format(np.std(std_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbw8J_HtP-Sc",
        "outputId": "d12dface-c8de-4d65-8b06-f078571f48c0"
      },
      "outputs": [],
      "source": [
        "print(acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hAFuuGKP-Sc"
      },
      "outputs": [],
      "source": [
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_list_k10_128.npy\", acc_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/std_list_k10_128.npy\", std_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_log_k10_128.npy\", acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83CW3hgGnu2c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwgENIx6nu4_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdIx-H1AXvLd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBTgovKxXvN0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s70VmYuWXvP5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
