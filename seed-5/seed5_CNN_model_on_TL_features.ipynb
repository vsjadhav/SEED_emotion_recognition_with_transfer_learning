{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0S39jznhLCi"
      },
      "source": [
        "# start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqoyoJ-sEMzU"
      },
      "outputs": [],
      "source": [
        "# we have already extrcated features with transfer learning and are saved in file seed5_extract_TL_features_inception_v3.py, \n",
        "# we will use those fetures which are already arranged in 8x9 map as an image to a cnn model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVATyGYSJ63C"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjgH2b5aKPaG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq9c9PTjw2hi",
        "outputId": "282ce9f0-1c7a-40f9-b5c5-ca03848ffc0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Mar 29 14:53:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 511.65       Driver Version: 511.65       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA T500        WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   47C    P8    N/A /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A     10956      C   ...NAGE\\Anaconda3\\python.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoHskheT0P6W",
        "outputId": "b8e3ab13-af67-44c3-a042-b7249b46059a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nNGdNV4-QGj",
        "outputId": "a571140b-45c7-4fe2-a6c1-f5a3e3b683da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available\", len(tf.config.experimental.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUKpGUlG_D7T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADp0Acw4_D9_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOyQiNeBiz7p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M45k_bW8iz7p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drQhJKOYiz7q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKIMonVJiz7q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1heuEHehTucj"
      },
      "source": [
        "### full train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GAxZFS5b_E-h",
        "outputId": "748a182c-db65-4197-8597-3893cde2f1dd",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "k_in_kfold = 5\n",
        "batch = 128\n",
        "\n",
        "acc_list = []\n",
        "std_list = []\n",
        "all_acc = []\n",
        "acc_log = {}\n",
        "flag_for_model_summary = 0\n",
        "# with tf.device('/device:GPU:0'):\n",
        "for subject in range(1,17):  # 15 models for 15 subjects, no inter subject training, only intra subject\n",
        "    K.clear_session()\n",
        "    start = time.time()\n",
        "    falx = np.empty((0, 8, 9, 2048))\n",
        "    gc.collect()\n",
        "    for exp_id in range(1,4):\n",
        "      temp = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{subject}_{exp_id}_X89.npy\")\n",
        "      falx = np.vstack([falx, temp])\n",
        "      temp = None\n",
        "\n",
        "#     one_falx_1 = falx#.reshape(1008, 8, 9, 1280)\n",
        "\n",
        "    # ###============= random select ============####\n",
        "    # permutation = np.random.permutation(one_y_1.shape[0])\n",
        "    # one_falx_2 = one_falx_1[permutation, :]\n",
        "    # one_falx = one_falx_2[0:3400]\n",
        "    # one_y_2 = one_y_1[permutation, :]\n",
        "    # one_y = one_y_2[0:3400]\n",
        "    # ###============= random select ============####\n",
        "    one_y = one_y_1\n",
        "#     one_falx = one_falx_1[:,:,:,:]\n",
        "\n",
        "    print(one_y.shape)\n",
        "    print(falx.shape)\n",
        "    # x_train, x_test, y_train, y_test = train_test_split(one_falx, one_y, test_size=0.25)\n",
        "    seed = 7\n",
        "    np.random.seed(seed)\n",
        "    kfold = StratifiedKFold(n_splits=k_in_kfold, shuffle=True, random_state=seed)\n",
        "    cvscores = []\n",
        "\n",
        "\n",
        "    # create model\n",
        "    for k,(train, test) in enumerate(kfold.split(falx, one_y.argmax(1))):\n",
        "        img_size = (img_rows, img_cols, 2048)\n",
        "\n",
        "\n",
        "        def create_base_network(input_dim):\n",
        "\n",
        "            seq = Sequential()\n",
        "            seq.add(Conv2D(16, 3, activation='relu', padding='same', name='conv1',\n",
        "                           input_shape=input_dim))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            seq.add(Conv2D(32, 2, activation='relu', padding='same', name='conv2'))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            # seq.add(Conv3D(32, 3, activation='relu', padding='same', name='conv3'))\n",
        "            seq.add(Conv2D(8, 1, activation='relu', padding='same', name='conv4'))\n",
        "            seq.add(MaxPooling2D(2, 2, name='pool1'))\n",
        "            seq.add(Flatten(name='fla1'))\n",
        "            seq.add(Dense(16, activation='relu', name='dense1'))#, kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "#             seq.add(Reshape((1, 64), name='reshape'))\n",
        "\n",
        "            return seq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        base_network = create_base_network(img_size)\n",
        "        input_1 = Input(shape=img_size)\n",
        "#         input_2 = Input(shape=img_size)\n",
        "#         input_3 = Input(shape=img_size)\n",
        "#         input_4 = Input(shape=img_size)\n",
        "#         input_5 = Input(shape=img_size)\n",
        "#         input_6 = Input(shape=img_size)\n",
        "\n",
        "\n",
        "\n",
        "#         out_all = Concatenate(axis=1)(base_network(input_1))\n",
        "#         lstm_layer = LSTM(32, name='lstm')(out_all)\n",
        "        out_layer = Dense(5, activation='softmax', name='out')(base_network(input_1))\n",
        "        model = Model(input_1, out_layer)\n",
        "        # model.summary()\n",
        "        if flag_for_model_summary==0:\n",
        "          print(model.summary())\n",
        "          flag_for_model_summary = 1\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                      optimizer=tf.keras.optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "        # Fit the model\n",
        "        x_train = falx[train]\n",
        "        y_train = one_y[train]\n",
        "\n",
        "        x_test = falx[test]\n",
        "        y_test = one_y[test]\n",
        "\n",
        "        history = model.fit(x_train, y_train,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            epochs=150, batch_size=batch, verbose=0,\n",
        "                            callbacks=[\n",
        "                                          tf.keras.callbacks.EarlyStopping(\n",
        "                                              monitor='val_accuracy',\n",
        "                                              patience=30,\n",
        "                                              restore_best_weights=True\n",
        "                                          )\n",
        "                                      ])\n",
        "\n",
        "        plt.plot(history.history['accuracy'], label='acc (training data)')\n",
        "        plt.plot(history.history['val_accuracy'], label='acc (validation data)')\n",
        "        plt.plot(history.history['loss'], label='loss (training data)')\n",
        "        plt.plot(history.history['val_loss'], label='loss (validation data)')\n",
        "        plt.title('training visualisation')\n",
        "        plt.ylabel('Value')\n",
        "        plt.xlabel('No. epoch')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # evaluate the model\n",
        "\n",
        "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "        print(\"%.2f%%\" % (scores[1] * 100)) # Accuracy\n",
        "        all_acc.append(scores[1] * 100)\n",
        "\n",
        "        y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(x_test))))\n",
        "        cm = confusion_matrix(y_test.argmax(1), y_pred)\n",
        "        clr = classification_report(y_test.argmax(1), y_pred, target_names=([\"0\",\"1\",\"2\",\"3\",\"4\"]))\n",
        "        plt.figure(figsize=(7, 7))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
        "        plt.xticks(np.arange(5) + 0.5, ([\"0\",\"1\",\"2\",\"3\",\"4\"]))\n",
        "        plt.yticks(np.arange(5) + 0.5, ([\"0\",\"1\",\"2\",\"3\",\"4\"]))\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "        print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "\n",
        "        print(f\"subject_no.:{subject}'s kfold:{k+1} completed\")\n",
        "\n",
        "\n",
        "    # print(\"all acc: {}\".format(all_acc))\n",
        "    print(\"mean acc: {}\".format(np.mean(all_acc)))\n",
        "    print(\"std acc: {}\".format(np.std(all_acc)))\n",
        "    acc_list.append(np.mean(all_acc))\n",
        "    std_list.append(np.std(all_acc))\n",
        "    print(\"subject_no.： {}\".format(subject))\n",
        "    acc_log[subject]  = all_acc\n",
        "    all_acc = []\n",
        "    end = time.time()\n",
        "    print(\"%.2f\" % (end - start))   # run time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RhyjaeTiz7v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-onNZqWwiz7v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oB_6KO6Qiz7v",
        "outputId": "601e4629-2f11-4571-e231-930170ed7f4c"
      },
      "outputs": [],
      "source": [
        "print('Acc_all: {}'.format(acc_list))\n",
        "print('Std_all: {}'.format(std_list))\n",
        "print(\"Acc_mean: {}\".format(np.mean(acc_list)))\n",
        "print(\"Std_all: {}\".format(np.std(std_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i3eLBe9Siz7v",
        "outputId": "418c9d95-29a3-4392-9e1d-4f5559412cbb"
      },
      "outputs": [],
      "source": [
        "print(acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oySTEw2M_E-h"
      },
      "outputs": [],
      "source": [
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_list_k5_128.npy\", acc_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/std_list_k5_128.npy\", std_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/acc_log_k5_128.npy\", acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diNO1ByWATKl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KybcYEddATM7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k8_2bJRATPw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whnNNsbItpYG"
      },
      "source": [
        "# balanced data k5 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOlFyz_oiz7z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRvnA80cp-iJ",
        "outputId": "4d27f3a0-98b5-4b6f-e2df-975a8f639253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsNlt7MHp-iK"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"./drive/MyDrive/seed_4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO0aqG0bp-iK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import Flatten, Dense, Concatenate, Reshape, LSTM\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,  classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "import keras\n",
        "# import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "from keras import backend as K\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6Z1HInAp-iK"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI0x8OOPp-iK"
      },
      "outputs": [],
      "source": [
        "num_classes = 4\n",
        "batch_size = 64\n",
        "img_rows, img_cols, fft_length, num_chan = 8, 9, 2048, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRr2STAMp-iK",
        "outputId": "97117f93-5d5d-4fab-da41-a3be2d7ff8d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(491,)\n",
            "(481,)\n",
            "(475,)\n"
          ]
        }
      ],
      "source": [
        "i = 1\n",
        "\n",
        "# X = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/{i}_{i}_X_1D.npy\")\n",
        "for exp in range(1,4):\n",
        "  y = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{i}_{exp}_y.npy\")\n",
        "  print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKqI4esEp-iL"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "y = []\n",
        "for exp in range(1,4):\n",
        "  temp_y = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{i}_{exp}_y.npy\")\n",
        "  for label in temp_y:\n",
        "    y.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhgXdENCp-iL"
      },
      "outputs": [],
      "source": [
        "temp = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d49i_mFSp-iL",
        "outputId": "76b19e80-f1c3-4da4-98ca-dbd1df74b9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n"
          ]
        }
      ],
      "source": [
        "c = gc.collect()\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X01IYHhFp-iL"
      },
      "outputs": [],
      "source": [
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jdb6eSxp-iL",
        "outputId": "c19b8a04-7ccb-40c0-b9ef-c303a4fff28d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2925,)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96_J67MGp-iL",
        "outputId": "abc6dea6-b4bb-48d1-9bea-3ea99b559063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2925,)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "(array([0., 1., 2., 3.]), array([793, 797, 716, 619]))\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# one_y = np.array([y[:1697]] * 3).reshape((-1,))\n",
        "# one_y = to_categorical(one_y, num_classes)\n",
        "one_y_1 = np.array([y[:]]*1).reshape((-1,))\n",
        "print(one_y_1.shape)\n",
        "# for i in range(3378):\n",
        "#   if one_y_1[i] != y[(i%1126)]:\n",
        "#     print(\"break\")\n",
        "#     break\n",
        "print(one_y_1[0:10])\n",
        "print(np.unique(one_y_1, return_counts= True))\n",
        "one_y_1 = to_categorical(one_y_1, num_classes)\n",
        "print(one_y_1[0:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jM3KqPhqQuN"
      },
      "outputs": [],
      "source": [
        "data_balance_info = np.unique(one_y_1.argmax(1), return_counts= True)\n",
        "min_data = np.min(data_balance_info[1])\n",
        "data_balance_diff = [i-min_data for i in data_balance_info[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH1RfJgfqewa",
        "outputId": "fd8a5696-45b3-47eb-ec2c-af77809a50b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3]), array([793, 797, 716, 619]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_balance_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5XfmmSgqQxS",
        "outputId": "51cb0abb-1c2a-4b21-f502-0c7595fbd57e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[174, 178, 97, 0]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_balance_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgdQOrn9qQ0B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J1s2ykcsp-iM",
        "outputId": "2837f672-94a7-47a2-eabb-44fc10437020",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "k_in_kfold = 5\n",
        "batch = 128\n",
        "\n",
        "acc_list = []\n",
        "std_list = []\n",
        "all_acc = []\n",
        "acc_log = {}\n",
        "flag_for_model_summary = 0\n",
        "# with tf.device('/device:GPU:0'):\n",
        "for subject in range(1,16):  # 15 models for 15 subjects, no inter subject training, only intra subject\n",
        "    K.clear_session()\n",
        "    start = time.time()\n",
        "    falx = np.empty((0, 8, 9, 2048))\n",
        "    for exp_id in range(1,4):\n",
        "      temp = np.load(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/{subject}_{exp_id}_X89.npy\")\n",
        "      falx = np.vstack([falx, temp])\n",
        "      temp = None\n",
        "\n",
        "#     one_falx_1 = falx#.reshape(1008, 8, 9, 1280)\n",
        "\n",
        "    # ###============= random select ============####\n",
        "    # permutation = np.random.permutation(one_y_1.shape[0])\n",
        "    # one_falx_2 = one_falx_1[permutation, :]\n",
        "    # one_falx = one_falx_2[0:3400]\n",
        "    # one_y_2 = one_y_1[permutation, :]\n",
        "    # one_y = one_y_2[0:3400]\n",
        "    # ###============= random select ============####\n",
        "    one_y = one_y_1.copy()\n",
        "#     one_falx = one_falx_1[:,:,:,:]\n",
        "\n",
        "    print(f\"lable count diff. with min. count:{data_balance_diff}\")\n",
        "    print(one_y.shape)\n",
        "    print(falx.shape)\n",
        "    print(f\"data balance-> {np.unique(one_y.argmax(1), return_counts= True)}\")\n",
        "\n",
        "    for label,diff in enumerate(data_balance_diff):\n",
        "        y_argmax = one_y.argmax(1)\n",
        "        for m in range(diff):\n",
        "            index = np.random.randint(len(y_argmax)-1)\n",
        "            while y_argmax[index]!=label:\n",
        "                index = np.random.randint(len(y_argmax)-1)\n",
        "            y_argmax = np.delete(y_argmax, index, axis=0)\n",
        "            one_y = np.delete(one_y, index, axis=0)\n",
        "            falx = np.delete(falx, index, axis=0)\n",
        "\n",
        "    print(\"after data balancing\")\n",
        "    print(one_y.shape)\n",
        "    print(falx.shape)\n",
        "    print(f\"data balance-> {np.unique(one_y.argmax(1), return_counts= True)}\")\n",
        "    # x_train, x_test, y_train, y_test = train_test_split(one_falx, one_y, test_size=0.25)\n",
        "    seed = 7\n",
        "    np.random.seed(seed)\n",
        "    kfold = StratifiedKFold(n_splits=k_in_kfold, shuffle=True, random_state=seed)\n",
        "    cvscores = []\n",
        "\n",
        "\n",
        "    # create model\n",
        "    for k,(train, test) in enumerate(kfold.split(falx, one_y.argmax(1))):\n",
        "        img_size = (img_rows, img_cols, 2048)\n",
        "\n",
        "\n",
        "        def create_base_network(input_dim):\n",
        "\n",
        "            seq = Sequential()\n",
        "            seq.add(Conv2D(16, 3, activation='relu', padding='same', name='conv1',\n",
        "                           input_shape=input_dim))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            seq.add(Conv2D(32, 2, activation='relu', padding='same', name='conv2'))#, kernel_regularizer=keras.regularizers.l2(0.001)))\n",
        "            # seq.add(Conv3D(32, 3, activation='relu', padding='same', name='conv3'))\n",
        "            seq.add(Conv2D(8, 1, activation='relu', padding='same', name='conv4'))\n",
        "            seq.add(MaxPooling2D(2, 2, name='pool1'))\n",
        "            seq.add(Flatten(name='fla1'))\n",
        "            seq.add(Dense(16, activation='relu', name='dense1'))#, kernel_regularizer=keras.regularizers.l2(0.01)))\n",
        "#             seq.add(Reshape((1, 64), name='reshape'))\n",
        "\n",
        "            return seq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        base_network = create_base_network(img_size)\n",
        "        input_1 = Input(shape=img_size)\n",
        "#         input_2 = Input(shape=img_size)\n",
        "#         input_3 = Input(shape=img_size)\n",
        "#         input_4 = Input(shape=img_size)\n",
        "#         input_5 = Input(shape=img_size)\n",
        "#         input_6 = Input(shape=img_size)\n",
        "\n",
        "\n",
        "\n",
        "#         out_all = Concatenate(axis=1)(base_network(input_1))\n",
        "#         lstm_layer = LSTM(32, name='lstm')(out_all)\n",
        "        out_layer = Dense(4, activation='softmax', name='out')(base_network(input_1))\n",
        "        model = Model(input_1, out_layer)\n",
        "        # model.summary()\n",
        "        if flag_for_model_summary==0:\n",
        "          print(model.summary())\n",
        "          flag_for_model_summary = 1\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                      optimizer=tf.keras.optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "        # Fit the model\n",
        "        x_train = falx[train]\n",
        "        y_train = one_y[train]\n",
        "\n",
        "        x_test = falx[test]\n",
        "        y_test = one_y[test]\n",
        "\n",
        "        history = model.fit(x_train, y_train,\n",
        "                            validation_data=(x_test, y_test),\n",
        "                            epochs=150, batch_size=batch, verbose=0,\n",
        "                            callbacks=[\n",
        "                                          tf.keras.callbacks.EarlyStopping(\n",
        "                                              monitor='val_accuracy',\n",
        "                                              patience=30,\n",
        "                                              restore_best_weights=True\n",
        "                                          )\n",
        "                                      ])\n",
        "\n",
        "        plt.plot(history.history['accuracy'], label='acc (training data)')\n",
        "        plt.plot(history.history['val_accuracy'], label='acc (validation data)')\n",
        "        plt.plot(history.history['loss'], label='loss (training data)')\n",
        "        plt.plot(history.history['val_loss'], label='loss (validation data)')\n",
        "        plt.title('training visualisation')\n",
        "        plt.ylabel('Value')\n",
        "        plt.xlabel('No. epoch')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # evaluate the model\n",
        "\n",
        "        scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "        print(\"%.2f%%\" % (scores[1] * 100)) # Accuracy\n",
        "        all_acc.append(scores[1] * 100)\n",
        "\n",
        "        y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(x_test))))\n",
        "        cm = confusion_matrix(y_test.argmax(1), y_pred)\n",
        "        clr = classification_report(y_test.argmax(1), y_pred, target_names=([\"0\",\"1\",\"2\",\"3\"]))\n",
        "        plt.figure(figsize=(7, 7))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
        "        plt.xticks(np.arange(4) + 0.5, ([\"0\",\"1\",\"2\",\"3\"]))\n",
        "        plt.yticks(np.arange(4) + 0.5, ([\"0\",\"1\",\"2\",\"3\"]))\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "        print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "\n",
        "        print(f\"subject_no.:{subject}'s kfold:{k+1} completed\")\n",
        "\n",
        "\n",
        "    # print(\"all acc: {}\".format(all_acc))\n",
        "    print(\"mean acc: {}\".format(np.mean(all_acc)))\n",
        "    print(\"std acc: {}\".format(np.std(all_acc)))\n",
        "    acc_list.append(np.mean(all_acc))\n",
        "    std_list.append(np.std(all_acc))\n",
        "    print(\"subject_no.： {}\".format(subject))\n",
        "    acc_log[subject]  = all_acc\n",
        "    all_acc = []\n",
        "    end = time.time()\n",
        "    print(\"%.2f\" % (end - start))   # run time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORG-mzEup-iM",
        "outputId": "eddcaabc-2f09-46f3-c76a-d543dc904dc7"
      },
      "outputs": [],
      "source": [
        "print('Acc_all: {}'.format(acc_list))\n",
        "print('Std_all: {}'.format(std_list))\n",
        "print(\"Acc_mean: {}\".format(np.mean(acc_list)))\n",
        "print(\"Std_all: {}\".format(np.std(std_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru4GeqMXp-iN",
        "outputId": "368e1df6-c05d-45b4-bba3-1f150312f6ae"
      },
      "outputs": [],
      "source": [
        "print(acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeoW6ARWp-iN"
      },
      "outputs": [],
      "source": [
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/balanced_acc_list_k5_128.npy\", acc_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/balanced_std_list_k5_128.npy\", std_list)\n",
        "np.save(f\"{dataset_path}/my_extracted_features/spectrogram(224_224_3)/TL_inception_v3/balanced_acc_log_k5_128.npy\", acc_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPTJdu5Stifp"
      },
      "outputs": [],
      "source": [
        "!kill -9 -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbX4OH0Sw3H0"
      },
      "outputs": [],
      "source": [
        "print(\"not killed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHXZ3y2Eiz71"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M95qQousiz71"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "V0S39jznhLCi",
        "VtlswIPqiz69",
        "xGtSp4_ADKkP"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
